{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d450637-5a47-435a-9d7a-7534245cc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import statistics\n",
    "import collections\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c504b2-d27b-4639-aa72-2dec548614ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上位のキーポイントの相対関係を全て調べて多数決を取ることでノイズに強くする\n",
    "def vote_point(query_kp, map_kp, point_num):\n",
    "\n",
    "    # 点i, jの相対角度と相対長さを格納する配列\n",
    "    deg_cand = np.zeros((point_num, point_num))  \n",
    "    len_cand = np.zeros((point_num, point_num))\n",
    "\n",
    "    # 全ての点のサイズ比，相対角度を求める\n",
    "    for i in range(point_num):\n",
    "        for j in range(i+1, point_num):\n",
    "            # クエリ画像から特徴点間の角度と距離を計算\n",
    "            q_x1, q_y1 = query_kp[i].pt\n",
    "            q_x2, q_y2 = query_kp[j].pt\n",
    "            q_deg = math.atan2(q_y2 - q_y1, q_x2 - q_x1) * 180 / math.pi\n",
    "            q_len = math.sqrt((q_x2 - q_x1) ** 2 + (q_y2 - q_y1) ** 2)\n",
    "\n",
    "            # マップ画像から特徴点間の角度と距離を計算\n",
    "            m_x1, m_y1 = map_kp[i].pt\n",
    "            m_x2, m_y2 = map_kp[j].pt\n",
    "            m_deg = math.atan2(m_y2 - m_y1, m_x2 - m_x1) * 180 / math.pi\n",
    "            m_len = math.sqrt((m_x2 - m_x1) ** 2 + (m_y2 - m_y1) ** 2)\n",
    "\n",
    "            #print(q_x1, q_y1, q_x2, q_y2, q_deg, q_len)\n",
    "            #print(m_x1, m_y1, m_x2, m_y2, m_deg, m_len)\n",
    "\n",
    "            # 2つの画像の相対角度と距離\n",
    "            deg_value = q_deg - m_deg\n",
    "            if deg_value < 0:\n",
    "                deg_value += 360\n",
    "            if m_len <= 0:\n",
    "                continue\n",
    "            size_rate = q_len/m_len\n",
    "\n",
    "            deg_cand[i][j] = deg_value\n",
    "            deg_cand[j][i] = deg_value\n",
    "            len_cand[i][j] = size_rate\n",
    "            len_cand[j][i] = size_rate\n",
    "\n",
    "    # print(deg_cand)\n",
    "    # print(len_cand)\n",
    "\n",
    "    # 多数決を取る\n",
    "    # ある点iについて，j, kとの相対関係が一致するかを各jについて調べる\n",
    "    cand_count = np.zeros((point_num, point_num))\n",
    "    size_range_min = 0.3  # 明らかに違う比率の結果を弾く重要パラメータ\n",
    "    size_range_max = 3  # 明らかに違う比率の結果を弾く重要パラメータ\n",
    "    dif_range = 0.05  # 重要パラメータ\n",
    "\n",
    "    for i in range(len(deg_cand)):\n",
    "        for j in range(len(deg_cand)):\n",
    "            # 明らかに違う比率の結果を弾く\n",
    "            if len_cand[i][j] < size_range_min or len_cand[i][j] > size_range_max:\n",
    "                    continue\n",
    "\n",
    "            for k in range(len(deg_cand)):\n",
    "                # 明らかに違う比率の結果を弾く\n",
    "                if len_cand[i][k] < size_range_min or len_cand[i][k] > size_range_max:\n",
    "                    continue\n",
    "\n",
    "                # 誤差がある範囲以下の値なら同じ値とみなす\n",
    "                deg_dif = np.abs(deg_cand[i][k] - deg_cand[i][j])\n",
    "                size_dif = np.abs(len_cand[i][k] - len_cand[i][j])\n",
    "                if deg_dif <= deg_cand[i][j]*dif_range and size_dif <= len_cand[i][j]*dif_range:\n",
    "                    cand_count[i][j] += 1\n",
    "\n",
    "    # print(cand_count)\n",
    "\n",
    "    # どの2点も同じ相対関係になかった場合\n",
    "    if np.max(cand_count) <= 1:\n",
    "        # print(\"[error] no matching point pair\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # もっとも多く相対関係が一致する2点を取ってくる\n",
    "    maxidx = np.unravel_index(np.argmax(cand_count), cand_count.shape)\n",
    "    deg_value = deg_cand[maxidx]\n",
    "    size_rate = len_cand[maxidx]\n",
    "\n",
    "    return deg_value, size_rate, maxidx[0], maxidx[1]\n",
    "\n",
    "\n",
    "# 最終的な描画関数\n",
    "def draw_final(result_img, m_xcenter, m_ycenter, deg_value, width_query):\n",
    "    # 中心点の描画\n",
    "    cv2.circle(result_img, (int(m_xcenter) + width_query, int(m_ycenter)), 20, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "    # 向きの計算，矢印描画\n",
    "    deg_front = - deg_value * math.pi / 180 - math.pi/2\n",
    "    q_xfront = m_xcenter + 200 * math.cos(deg_front)\n",
    "    q_yfront = m_ycenter + 200 * math.sin(deg_front)\n",
    "    cv2.arrowedLine(result_img, (int(m_xcenter) + width_query, int(m_ycenter)),\n",
    "                    (int(q_xfront) + width_query, int(q_yfront)), color=(255, 0, 0), thickness=15)\n",
    "\n",
    "    final_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('img', final_img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd2ca0c-3895-45ec-98ef-ae85c9df2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------matching start----------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------matching start----------\")\n",
    "time_start = time.time()\n",
    "akaze = cv2.AKAZE_create()\n",
    "#akaze = cv2.ORB_create()\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# query = カメラ画像\n",
    "# map = マップ\n",
    "\n",
    "# gamma補正の関数\n",
    "gamma = 1.8\n",
    "gamma_cvt = np.zeros((256,1),dtype = 'uint8')\n",
    "for i in range(256):\n",
    "    gamma_cvt[i][0] = 255 * (float(i)/255) ** (1.0/gamma)\n",
    "\n",
    "# 画像の拡大，縮小の割合(重要パラメータ)\n",
    "expand_query = 0.5\n",
    "expand_map = 2\n",
    "\n",
    "# クエリ画像を読み込んで特徴量計算\n",
    "query_img = cv2.imread('./template.png', 0)\n",
    "query_img = cv2.LUT(query_img, gamma_cvt)\n",
    "# cv2.imwrite('./log/input_img.png', query_img)\n",
    "query_img = cv2.resize(query_img, (int(query_img.shape[1] * expand_query), \n",
    "                       int(query_img.shape[0] * expand_query)))\n",
    "height_query, width_query = query_img.shape[:2]\n",
    "kp_query, des_query = akaze.detectAndCompute(query_img, None)\n",
    "# print('[time] feature calculation query: ', time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094f1672-144e-461e-8cac-f4c484bd069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    # マップ画像を読み込んで特徴量計算\n",
    "    # map_img = cv2.imread('./img/map/field.png', 0)\n",
    "    ret, map_img = capture.read()\n",
    "    map_img = cv2.resize(map_img, (int(map_img.shape[1] * expand_map), \n",
    "                            int(map_img.shape[0] * expand_map)))\n",
    "    height_map, width_map = map_img.shape[:2]\n",
    "    # cv2.imwrite('./log/fig/sample_img.png', sample_img)\n",
    "    kp_map, des_map = akaze.detectAndCompute(map_img, None)\n",
    "    # print('[time] feature calculation map: ', time.time() - time_start)\n",
    "\n",
    "    # 特徴量マッチング実行，k近傍法\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des_query, des_map, k=2)\n",
    "    # print('[time] feature matching: ', time.time() - time_start)\n",
    "\n",
    "    # マッチング精度が高いもののみ抽出\n",
    "    ratio = 0.8  # 重要パラメータ\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    # 対応点が１個以下なら相対関係を求められないのでNoneを返す\n",
    "    if len(good) <= 1:\n",
    "        # print(\"[error] can't detect matching feature point\")\n",
    "        continue\n",
    "\n",
    "    # 精度が高かったもののうちスコアが高いものから指定個取り出す\n",
    "    good = sorted(good, key=lambda x: x[0].distance)\n",
    "    # print(\"valid point number: \", len(good))  # これがあまりに多すぎたり少なすぎたりする場合はパラメータを変える\n",
    "    point_num = 20  # 上位何個の点をマッチングに使うか（重要パラメータ）\n",
    "    if len(good) < point_num:\n",
    "        point_num = len(good)  # もし20個なかったら全て使う\n",
    "\n",
    "    # マッチング結果の描画\n",
    "    result_img = cv2.drawMatchesKnn(query_img, kp_query, map_img, kp_map, good[:point_num], None, flags=0)\n",
    "    img_matching = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('img', img_matching)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # print('[time] draw mid result: ', time.time() - time_start)\n",
    "\n",
    "    #------ これ以降位置と向きの計算 -------\n",
    "    query_kp = []\n",
    "    map_kp = []\n",
    "\n",
    "    # 2つの画像で対応するキーポイントを抽出\n",
    "    for p in good[:point_num]:\n",
    "        query_kp.append(kp_query[p[0].queryIdx])\n",
    "        map_kp.append(kp_map[p[0].trainIdx])\n",
    "\n",
    "    # 投票によって２画像の相対角度，相対比率，もっとも一致度の高い点のペアが計算される\n",
    "    deg_value, size_rate, m1, m2 = vote_point(query_kp, map_kp, point_num)\n",
    "    if deg_value is None:\n",
    "        continue\n",
    "\n",
    "    # print(f\"calcurated deg: {deg_value}, size_rate: {size_rate}\")\n",
    "    # print(f\"two matching point index: {m1}, {m2}\")\n",
    "    # print('[time] point calculation: ', time.time() - time_start)\n",
    "\n",
    "    # クエリ画像の1点目とクエリ画像の中心の相対的な関係\n",
    "    q_x1, q_y1 = query_kp[m1].pt\n",
    "    m_x1, m_y1 = map_kp[m1].pt\n",
    "    q_xcenter = int(width_query/2)\n",
    "    q_ycenter = int(height_query/2)\n",
    "    q_center_deg = math.atan2(q_ycenter - q_y1, q_xcenter - q_x1) * 180 / math.pi\n",
    "    q_center_len = math.sqrt((q_xcenter - q_x1) ** 2 + (q_ycenter - q_y1) ** 2)\n",
    "    #print(q_xcenter, q_ycenter, q_center_deg, q_center_len)\n",
    "\n",
    "    # 上の関係をマップ画像上のパラメータに変換\n",
    "    m_center_deg = q_center_deg - deg_value\n",
    "    m_center_len = q_center_len/size_rate\n",
    "    #print(t_center_deg, t_center_len)\n",
    "\n",
    "    # 中心点のマップ画像上での位置\n",
    "    m_center_rad = m_center_deg * math.pi / 180\n",
    "    m_xcenter = m_x1 + m_center_len * math.cos(m_center_rad)\n",
    "    m_ycenter = m_y1 + m_center_len * math.sin(m_center_rad)\n",
    "    # print(m_center_rad, math.cos(m_center_rad), math.sin(m_center_rad), m_xcenter, m_ycenter)\n",
    "\n",
    "    # 算出された値が正しい座標範囲に入っているかどうか\n",
    "    if (m_xcenter < 0) or (m_xcenter > width_map):\n",
    "        print(\"[error] invalid x value\")\n",
    "        continue\n",
    "    if (m_ycenter < 0) or (m_ycenter > height_map):\n",
    "        print(\"[error] invalid y value\")\n",
    "        continue\n",
    "    if (deg_value < 0) or (deg_value > 360):\n",
    "        print(\"[error] invalid deg value\")\n",
    "        continue\n",
    "\n",
    "    x_current = int(m_xcenter/expand_map)\n",
    "    y_current = int(m_ycenter/expand_map)\n",
    "    drc_current = deg_value\n",
    "\n",
    "    # print('*****detection scceeded!*****')\n",
    "    # print('[time] final time: {:.4f} (s)'.format(time.time() - time_start))\n",
    "    # print(\"final output score-> x: {}, y: {}, drc: {:.2f}°\".format(x_current, y_current, drc_current))\n",
    "\n",
    "    # 中心点描画\n",
    "    draw_final(result_img, m_xcenter, m_ycenter, deg_value, width_query)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412de401-8307-4069-a86e-b9abefe02b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
